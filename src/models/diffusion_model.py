from abc import abstractmethod
import torch
from torch import nn


class TimeEmbedding(nn.Module):
    """Diffusion model time embedding interface."""
    def __init__(self):
        super().__init__()

    @abstractmethod
    def forward(self, t: torch.Tensor) -> torch.Tensor:
        """
        Forward pass for time embedding.

        Args:
            t (torch.Tensor): Time step tensor.

        Returns:
            torch.Tensor: Embedded time tensor.
        """
        pass


class DenoisingModel(nn.Module):
    """Denoising model interface.
    A denoising model is a neural network that takes an input tensor and a time embedding tensor,
    and outputs a noise tensor.
    """
    def __init__(self):
        super().__init__()

    @abstractmethod
    def forward(self, x: torch.Tensor, t_emb: torch.Tensor) -> torch.Tensor:
        """
        Forward pass of the denoising model.

        Args:
            x (torch.Tensor): Input tensor.
            t_emb (torch.Tensor): Time embedding tensor.

        Returns:
            torch.Tensor: Output tensor after applying the denoising process.
        """
        pass


class DiffusionModel(nn.Module):
    def __init__(
        self,
        denoising_model: DenoisingModel,
        embedding_model: TimeEmbedding,
        input_shape: tuple,
        num_timesteps: int = 1000,
        beta_min: float = 1e-4,
        beta_max: float = 0.02,
    ):
        super().__init__()
        self.denoising_model = denoising_model
        self.embedding_model = embedding_model

        self.input_shape = input_shape
        self.num_timesteps = num_timesteps

        self.beta_min = beta_min
        self.beta_max = beta_max
        self._precompute_parameters()

    def _precompute_parameters(self):
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        dtype = torch.float32

        self.betas = torch.linspace(self.beta_min, self.beta_max, self.num_timesteps, device=device, dtype=dtype)
        self.alphas = 1.0 - self.betas
        self.alpha_bars = torch.cumprod(self.alphas, dim=0)

        # Evita error por tamaÃ±os (alpha_bars[:-1] vs alpha_bars[1:])
        numerator = self.betas[:-1] * (1.0 - self.alpha_bars[:-1])
        denominator = (1.0 - self.alpha_bars[1:]).clamp(min=1e-20)
        beta_tilde = numerator / denominator

        self.beta_tilde = torch.cat([beta_tilde, self.betas[-1:]])
        self.sigmas = torch.sqrt(self.beta_tilde)

    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        """
        Forward pass of the diffusion model (denoise process).

        Args:
            x (torch.Tensor): Input tensor.
            t (torch.Tensor): Time step tensor.

        Returns:
            torch.Tensor: Output tensor after applying the diffusion process.
        """
        with torch.no_grad():  # Avoid to generate gradients
            t_emb = self.embedding_model(t)
        return self.denoising_model(x, t_emb)

    def generate(self, num_samples: int) -> torch.Tensor:
        """
        Generate samples from the diffusion model.

        Args:
            num_samples (int): amount of samples to generate.

        Returns:
            torch.Tensor: images generated by the diffusion model. [num_samples, *input_shape]
        """
        self.eval()
        with torch.no_grad():
            initial_noise = torch.randn(num_samples, *self.input_shape)
            samples = initial_noise
            for t in range(self.num_timesteps, 0, -1):
                z = torch.randn_like(samples) if t > 1 else torch.zeros_like(samples)
                alpha_bar_t, beta_t, sigma_t = self._get_coefficents(t - 1)
                t_tensor = torch.full(
                    (num_samples,), t, device=samples.device, dtype=torch.long
                )
                predicted_error = self.forward(samples, t_tensor)
                samples = (
                    samples - beta_t * predicted_error / torch.sqrt(1.0 - alpha_bar_t)
                ) / torch.sqrt(1.0 - beta_t) + sigma_t * z

        return samples

    def _get_coefficents(self, t: torch.Tensor) -> tuple:
        """
        Get the coefficients for the diffusion process at a specific time step.

        Args:
            t (torch.Tensor): Time step tensor.

        Returns:
            tuple: (alpha_bar_t, beta_t) for the given time step.
        """
        alpha_bar_t = self.alpha_bars[t]
        beta_t = self.betas[t]
        sigma_t = self.sigmas[t]
        return alpha_bar_t, beta_t, sigma_t

    def forward_noising_step(self, data: torch.Tensor, noise: torch.Tensor, t: torch.Tensor) -> torch.Tensor:
        """
        Forward noising steps.

        Args:
            data (torch.Tensor): Input data.
            noise (torch.Tensor): Input error.
            t (torch.Tensor): Time step tensor.

        Returns:
            torch.Tensor: Output tensor after applying the diffusion process.
        """
        alpha_bar_t, _, _ = self._get_coefficents(t)
        alpha_bar_t_expanded = alpha_bar_t.view(-1, 1, 1, 1)
        noised_data = torch.sqrt(alpha_bar_t_expanded) * data + torch.sqrt(1.0 - alpha_bar_t_expanded) * noise
        return noised_data
